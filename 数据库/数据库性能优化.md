##MySQL批量SQL插入性能优化
对于一些数据量较大的系统，数据库面临的问题除了查询效率低下，还有就是数据入库时间长。特别像报表系统，每天花费在数据导入上的时间可能会长达几个小时或十几个小时之久。因此，优化数据库插入性能是很有意义的。

经过对MySQL innodb的一些性能测试，发现一些可以提高insert效率的方法，供大家参考参考。

-  一条SQL语句插入多条数据
  
常用的插入语句如：
<pre>
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('0', 'userid_0', 'content_0', 0);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('1', 'userid_1', 'content_1', 1);
</pre>
修改成：
<pre>
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('0', 'userid_0', 'content_0', 0), ('1', 'userid_1', 'content_1', 1);
</pre>
修改后的插入操作能够提高程序的插入效率。这里第二种SQL执行效率高的主要原因是合并后日志量（MySQL的binlog和innodb的事务让日志）减少了，降低日志刷盘的数据量和频率，从而提高效率。通过合并SQL语句，同时也能减少SQL语句解析的次数，减少网络传输的IO。
这里提供一些测试对比数据，分别是进行单条数据的导入与转化成一条SQL语句进行导入，分别测试1百、1千、1万条数据记录。
<table>
<tr><td>记录数</td><td>单条数据插入</td><td>合并数据</td></tr>
<tr><td>100</td><td>0.109s</td><td>0.009s</td></tr>
<tr><td>1000</td><td>1.432s</td><td>0.026s</td></tr>
<tr><td>10000</td><td>13.093s</td><td>0.755s</td></tr>
</table>

- 在事务中进行插入处理

把插入修改成：
<pre>
START TRANSACTION;
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('0', 'userid_0', 'content_0', 0);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('1', 'userid_1', 'content_1', 1);
...
COMMIT;
</pre>
使用事务可以提高数据的插入效率，这是因为进行一个INSERT操作时，MySQL内部会建立一个事务，在事务内才进行真正插入处理操作。通过使用事务可以减少创建事务的消耗，所有插入都在执行后才进行提交操作。
这里也提供了测试对比，分别是不使用事务与使用事务在记录数为1百、1千、1万的情况。
<table>
<tr><td>记录数</td><td>单条数据插入</td><td>事务插入</td></tr>
<tr><td>100</td><td>0.109s</td><td>0.015s</td></tr>
<tr><td>1000</td><td>1.432s</td><td>0.085s</td></tr>
<tr><td>10000</td><td>13.093s</td><td>1.003s</td></tr>
</table>

- 数据有序插入

数据有序的插入是指插入记录在主键上是有序排列，例如datetime是记录的主键：
<pre>
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('1', 'userid_1', 'content_1', 1);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('0', 'userid_0', 'content_0', 0);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('2', 'userid_2', 'content_2',2);
</pre>
修改成：
<pre>
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('0', 'userid_0', 'content_0', 0);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('1', 'userid_1', 'content_1', 1);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('2', 'userid_2', 'content_2',2);
</pre>
由于数据库插入时，需要维护索引数据，无序的记录会增大维护索引的成本。我们可以参照innodb使用的B+tree索引，如果每次插入记录都在索引的最后面，索引的定位效率很高，并且对索引调整较小；如果插入的记录在索引中间，需要B+tree进行分裂合并等处理，会消耗比较多计算资源，并且插入记录的索引定位效率会下降，数据量较大时会有频繁的磁盘操作。

下面提供随机数据与顺序数据的性能对比，分别是记录为1百、1千、1万、10万、100万。
<table>
<tr><td>记录数</td><td>单条数据插入(随机)</td><td>单条数据插入（有序）</td></tr>
<tr><td>100</td><td>0.137s</td><td>0.122s</td></tr>
<tr><td>1000</td><td>1.155s</td><td>1.277s</td></tr>
<tr><td>1万</td><td>13.118s</td><td>13.197s</td></tr>
<tr><td>10万</td><td>11.274s</td><td>10.554s</td></tr>
<tr><td>100万</td><td>51.522s</td><td>47.174s</td></tr>
</table>
从测试结果来看，该优化方法的性能有所提高，但是提高并不是很明显。

性能综合测试：这里提供了同时使用上面三种方法进行INSERT效率优化的测试。
<img src="youhua.jpg" />

从测试结果可以看到，合并数据+事务的方法在较小数据量时，性能提高是很明显的，数据量较大时（1千万以上），性能会急剧下降，这是由于此时数据量超过了innodb_buffer的容量，每次定位索引涉及较多的磁盘读写操作，性能下降较快。而使用合并数据+事务+有序数据的方式在数据量达到千万级以上表现依旧是良好，在数据量较大时，有序数据索引定位较为方便，不需要频繁对磁盘进行读写操作，所以可以维持较高的性能。

注意事项：

- SQL语句是有长度限制，在进行数据合并在同一SQL中务必不能超过SQL长度限制，通过max_allowed_packet配置可以修改，默认是1M，测试时修改为8M。
- 事务需要控制大小，事务太大可能会影响执行的效率。MySQL有innodb_log_buffer_size配置项，超过这个值会把innodb的数据刷到磁盘中，这时，效率会有所下降。所以比较好的做法是，在数据达到这个这个值前进行事务提交。

##MySQL Innodb日志机制深入分析
1.1. Log & Checkpoint
Innodb的事务日志是指Redo log，简称Log,保存在日志文件ib_logfile*里面。Innodb还有另外一个日志Undo log，但Undo log是存放在共享表空间里面的（ibdata*文件）。

由于Log和Checkpoint紧密相关，因此将这两部分合在一起分析。

名词解释：LSN，日志序列号，Innodb的日志序列号是一个64位的整型。

1.1.1. 写入机制
1.1.1.1. Log写入
LSN实际上对应日志文件的偏移量，新的LSN＝旧的LSN + 写入的日志大小。举例如下：

LSN＝1G，日志文件大小总共为600M，本次写入512字节，则实际写入操作为：

l 求出偏移量：由于LSN数值远大于日志文件大小，因此通过取余方式，得到偏移量为400M；

l 写入日志：找到偏移400M的位置，写入512字节日志内容，下一个事务的LSN就是1000000512；

1.1.1.2. Checkpoint写入
Innodb实现了Fuzzy Checkpoint的机制，每次取到最老的脏页，然后确保此脏页对应的LSN之前的LSN都已经写入日志文件，再将此脏页的LSN作为Checkpoint点记录到日志文件，意思就是“此LSN之前的LSN对应的日志和数据都已经写入磁盘文件”。恢复数据文件的时候，Innodb扫描日志文件，当发现LSN小于Checkpoint对应的LSN，就认为恢复已经完成。

Checkpoint写入的位置在日志文件开头固定的偏移量处，即每次写Checkpoint都覆盖之前的Checkpoint信息。

1.1.2. 管理机制
由于Checkpoint和日志紧密相关，将日志和Checkpoint一起说明，详细的实现机制如下：
<img src="日志周期.gif.png" />

Innodb的一条事务日志共经历4个阶段：

1） 创建阶段：事务创建一条日志；

2）日志刷盘：日志写入到磁盘上的日志文件；

3） 数据刷盘：日志对应的脏页数据写入到磁盘上的数据文件；

4）写CKP：日志被当作Checkpoint写入日志文件；

对应这4个阶段，系统记录了4个日志相关的信息，用于其它各种处理使用：

Log sequence number（LSN1）：当前系统LSN最大值，新的事务日志LSN将在此基础上生成（LSN1+新日志的大小）；

Log flushed up to（LSN2）：当前已经写入日志文件的LSN；

Oldest modified data log（LSN3）：当前最旧的脏页数据对应的LSN，写Checkpoint的时候直接将此LSN写入到日志文件；

Last checkpoint at（LSN4）：当前已经写入Checkpoint的LSN；

对于系统来说，以上4个LSN是递减的，即： LSN1>=LSN2>=LSN3>=LSN4.

具体的样例如下（使用show innodb status \G命令查看，Oldest modified data log没有显示）：
<pre>
---
LOG
---
Log sequence number 23 2605355359
Log flushed up to 23 2604861304
Last checkedpoint at 23 1990097397
0 pending log writes, 0 pending chkp writes
1276082 log i/o`s done,6814.09 log i/o`s/second
</pre>
1.1.3. 保护机制
Innodb的数据并不是实时写盘的，为了避免宕机时数据丢失，保证数据的ACID属性，Innodb至少要保证数据对应的日志不能丢失。对于不同的情况，Innodb采取不同的对策：

1）宕机导致日志丢失
Innodb有日志刷盘机制，可以通过innodb_flush_log_at_trx_commit参数进行控制；

2）日志覆盖导致日志丢失

Innodb日志文件大小是固定的，写入的时候通过取余来计算偏移量，这样存在两个LSN写入到同一位置的可能，后面写的把前面写得就覆盖了，以“写入机制”章节的样例为例，LSN＝100000000和LSN＝1600000000两个日志的偏移量是相同的了。这种情况下，为了保证数据一致性，必须要求LSN=1000000000对应的脏页数据都已经刷到磁盘中，也就是要求Last checkpoint对应的LSN一定要大于1000000000，否则覆盖后日志也没有了，数据也没有刷盘，一旦宕机，数据就丢失了。

为了解决第二种情况导致数据丢失的问题，Innodb实现了一套日志保护机制，详细实现如下：

--------------------------------------------------------------------------
->Ckp age ->Buf age ->Buf async->Buf sync->Ckp async->Ckp sync
--------------------------------------------------------------------------

上图中，直线代表日志空间（Log cap，约等于日志文件总大小*0.8，0.8是一个安全系数)，Ckp age和Buf age是两个浮动的点，Buf async、Buf sync、Ckp async、Ckp sync是几个固定的点。各个概念的含义如下：

----------

概念；计算；含义

Ckp age;LSN1- LSN4;还没有做Checkpoint的日志范围，若Ckp age超过日志空间，说明被覆盖的日志（LSN1－LSN4－Log cap）对应日志和数据“可能”还没有刷到磁盘上

Buf age；LSN1- LSN3；还没有将脏页刷盘的日志的范围，若Buf age超过日志空间，说明被覆盖的日志（LSN1－LSN3－Log cap）对应数据“肯定”还没有刷到磁盘上

Buf async；日志空间大小 * 7/8；强制将Buf age-Buf async的脏页刷盘，此时事务还可以继续执行，所以为async，对事务的执行速度没有直接影响（有间接影响，例如CPU和磁盘更忙了，事务的执行速度可能受到影响）

Buf sync;日志空间大小 * 15/16；强制将2*(Buf age-Buf async)的脏页刷盘，此时事务停止执行，所以为sync，由于有大量的脏页刷盘，因此阻塞的时间比Ckp sync要长。

Ckp async;日志空间大小 * 31/32;强制写Checkpoint，此时事务还可以继续执行，所以为async，对事务的执行速度没有影响（间接影响也不大，因为写Checkpoint的操作比较简单）

Ckp sync;日志空间大小 * 64/64;强制写Checkpoint，此时事务停止执行，所以为sync，但由于写Checkpoint的操作比较简单，即使阻塞，时间也很短

----------

当事务执行速度大于脏页刷盘速度时，Ckp age和Buf age会逐步增长，当达到async点的时候，强制进行脏页刷盘或者写Checkpoint，如果这样做还是赶不上事务执行的速度，则为了避免数据丢失，到达sync点的时候，会阻塞其它所有的事务，专门进行脏页刷盘或者写Checkpoint。

因此从理论上来说,只要事务执行速度大于脏页刷盘速度，最终都会触发日志保护机制，进而将事务阻塞，导致MySQL操作挂起。

由于写Checkpoint本身的操作相比写脏页要简单，耗费时间也要少得多，且Ckp sync点在Buf sync点之后，因此绝大部分的阻塞都是阻塞在了Buf sync点，这也是当事务阻塞的时候，IO很高的原因，因为这个时候在不断的刷脏页数据到磁盘。

##MySQL Innodb数据库性能实践——VARCHAR vs CHAR
学过数据库理论的读者，都应该还记得关于CHAR和VARCHAR的性能对比：CHAR比VARCHAR更快，因为CHAR是固定长度的，而VARCHAR需要增加一个长度标识，处理时需要多一次运算。

【总结】
基于额外的测试结果和分析，我个人认为一般情况下优先使用VARCHAR，特别是字符串的平均长度比最大长度要小很多的情况；当然，如果你的字符串本来就很短，例如只有10个字符，那么就优先选CHAR了。

##MySQL Sending data导致查询很慢的问题详细分析
【问题现象】

使用sphinx支持倒排索引，但sphinx从mysql查询源数据的时候，查询的记录数才几万条，但查询的速度非常慢，大概要4~5分钟左右

【处理过程】

- explain

首先怀疑索引没有建好，于是使用explain查看查询计划。

- show processlist;

explain看不出问题，那到底慢在哪里呢？
于是想到了使用 show processlist查看sql语句执行状态，查询结果如下：
<pre>
Id:459
User:mng
Host:127.0.0.1:45619
db:nanagement
Command:Query
Time:15
State:Sending data
Into:SELECT gp.id id,gp.platform_id platform_id,gp.game_id game_id,g.category_ud category_id,gt.paren
</pre>
发现很长一段时间，查询都处在 “Sending data”状态;查询一下“Sending data”状态的含义，原来这个状态的名称很具有误导性，所谓的“Sending data”并不是单纯的发送数据，而是包括“收集 + 发送 数据”。

这里的关键是为什么要收集数据，原因在于：mysql使用“索引”完成查询结束后，mysql得到了一堆的行id，如果有的列并不在索引中，mysql需要重新到“数据行”上将需要返回的数据读取出来返回个客户端。

- show profile

为了进一步验证查询的时间分布，于是使用了show profile命令来查看详细的时间分布
<b>首先打开配置：set profiling=on;
执行完查询后，使用show profiles查看query id;
使用show profile for query query_id查看详细信息</b>;

从结果可以看出，Sending data的状态执行了216s

- 排查对比
- 
经过以上步骤，已经确定查询慢是因为大量的时间耗费在了Sending data状态上，结合Sending data的定义，将目标聚焦在查询语句的返回列上面.

经过一 一排查，最后定为到一个description的列上，这个列的设计为：
<pre>
`description`varchar(8000) DEFAULT NULL COMMENT '游戏描述',
</pre>
于是采取了对比的方法，看看“不返回description的结果”如何。show profile的结果如下：

可以看出，不返回description的时候，查询时间只需要15s，返回的时候，需要216s，两者相差15倍

【原理研究】

一篇淘宝的文章很好的解释了相关原理：innodb使用大字段text，blob的一些优化建议
这里的关键信息是：<b>当Innodb的存储格式是 ROW_FORMAT=COMPACT (or ROW_FORMAT=REDUNDANT)的时候，Innodb只会存储前768字节的长度，剩余的数据存放到“溢出页”中</b>。
我们使用show table status来查看表的相关信息。从表的信息可以看到，平均一行大约1.5K，也就说大约1/10行会使用“溢出存储”，一旦采用了这种方式存储，返回数据的时候<b>本来是顺序读取的数据，就变成了随机读取</b>了，所以导致性能急剧下降。

另外，在测试过程中还发现，无论这条语句执行多少次，甚至将整个表select *几次，语句的执行速度都没有明显变化。这个表的数据和索引加起来才150M左右，而整个Innodb buffer pool有5G，缓存整张表绰绰有余，如果缓存了溢出页，性能应该大幅提高才对。<br>
但实测结果却并没有提高，因此从这个测试可以推论<b>Innodb并没有将溢出页（overflow page）缓存到内存里面</b>。<br>
这样的设计也是符合逻辑的，因为overflow page本来就是存放大数据的，如果也放在缓存里面，就会出现一次大数据列（blob、text、varchar）查询，可能就将所有的缓存都更新了，这样会导致其它普通的查询性能急剧下降。

【解决方法】

找到了问题的根本原因，解决方法也就不难了。有几种方法：

- 查询时去掉description的查询，但这受限于业务的实现，可能需要业务做较大调整
- 表结构优化，将descripion拆分到另外的表，这个改动较大，需要已有业务配合修改，且如果业务还是要继续查询这个description的信息，则优化后的性能也不会有很大提升。