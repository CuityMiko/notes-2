##MySQL批量SQL插入性能优化
对于一些数据量较大的系统，数据库面临的问题除了查询效率低下，还有就是数据入库时间长。特别像报表系统，每天花费在数据导入上的时间可能会长达几个小时或十几个小时之久。因此，优化数据库插入性能是很有意义的。

经过对MySQL innodb的一些性能测试，发现一些可以提高insert效率的方法，供大家参考参考。

-  一条SQL语句插入多条数据
  
常用的插入语句如：
<pre>
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('0', 'userid_0', 'content_0', 0);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('1', 'userid_1', 'content_1', 1);
</pre>
修改成：
<pre>
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('0', 'userid_0', 'content_0', 0), ('1', 'userid_1', 'content_1', 1);
</pre>
修改后的插入操作能够提高程序的插入效率。这里第二种SQL执行效率高的主要原因是合并后日志量（MySQL的binlog和innodb的事务让日志）减少了，降低日志刷盘的数据量和频率，从而提高效率。通过合并SQL语句，同时也能减少SQL语句解析的次数，减少网络传输的IO。

这里提供一些测试对比数据，分别是进行单条数据的导入与转化成一条SQL语句进行导入，分别测试1百、1千、1万条数据记录。
<table>
<tr><td>记录数</td><td>单条数据插入</td><td>合并数据</td></tr>
<tr><td>100</td><td>0.109s</td><td>0.009s</td></tr>
<tr><td>1000</td><td>1.432s</td><td>0.026s</td></tr>
<tr><td>10000</td><td>13.093s</td><td>0.755s</td></tr>
</table>

- 在事务中进行插入处理

把插入修改成：
<pre>
START TRANSACTION;
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('0', 'userid_0', 'content_0', 0);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('1', 'userid_1', 'content_1', 1);
...
COMMIT;
</pre>
使用事务可以提高数据的插入效率，这是因为进行一个INSERT操作时，MySQL内部会建立一个事务，在事务内才进行真正插入处理操作。通过使用事务可以减少创建事务的消耗，所有插入都在执行后才进行提交操作。
这里也提供了测试对比，分别是不使用事务与使用事务在记录数为1百、1千、1万的情况。
<table>
<tr><td>记录数</td><td>单条数据插入</td><td>事务插入</td></tr>
<tr><td>100</td><td>0.109s</td><td>0.015s</td></tr>
<tr><td>1000</td><td>1.432s</td><td>0.085s</td></tr>
<tr><td>10000</td><td>13.093s</td><td>1.003s</td></tr>
</table>

- 数据有序插入

数据有序的插入是指插入记录在主键上是有序排列，例如datetime是记录的主键：
<pre>
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('1', 'userid_1', 'content_1', 1);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('0', 'userid_0', 'content_0', 0);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('2', 'userid_2', 'content_2',2);
</pre>
修改成：
<pre>
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('0', 'userid_0', 'content_0', 0);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('1', 'userid_1', 'content_1', 1);
INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) 
    VALUES ('2', 'userid_2', 'content_2',2);
</pre>
由于数据库插入时，需要维护索引数据，无序的记录会增大维护索引的成本。我们可以参照innodb使用的B+tree索引，如果每次插入记录都在索引的最后面，索引的定位效率很高，并且对索引调整较小；如果插入的记录在索引中间，需要B+tree进行分裂合并等处理，会消耗比较多计算资源，并且插入记录的索引定位效率会下降，数据量较大时会有频繁的磁盘操作。

下面提供随机数据与顺序数据的性能对比，分别是记录为1百、1千、1万、10万、100万。
<table>
<tr><td>记录数</td><td>单条数据插入(随机)</td><td>单条数据插入（有序）</td></tr>
<tr><td>100</td><td>0.137s</td><td>0.122s</td></tr>
<tr><td>1000</td><td>1.155s</td><td>1.277s</td></tr>
<tr><td>1万</td><td>13.118s</td><td>13.197s</td></tr>
<tr><td>10万</td><td>11.274s</td><td>10.554s</td></tr>
<tr><td>100万</td><td>51.522s</td><td>47.174s</td></tr>
</table>
从测试结果来看，该优化方法的性能有所提高，但是提高并不是很明显。

性能综合测试：这里提供了同时使用上面三种方法进行INSERT效率优化的测试。
<img src="youhua.jpg" />

从测试结果可以看到，合并数据+事务的方法在较小数据量时，性能提高是很明显的，数据量较大时（1千万以上），性能会急剧下降，这是由于此时数据量超过了innodb_buffer的容量，每次定位索引涉及较多的磁盘读写操作，性能下降较快。而使用合并数据+事务+有序数据的方式在数据量达到千万级以上表现依旧是良好，在数据量较大时，有序数据索引定位较为方便，不需要频繁对磁盘进行读写操作，所以可以维持较高的性能。

注意事项：

- SQL语句是有长度限制，在进行数据合并在同一SQL中务必不能超过SQL长度限制，通过max_allowed_packet配置可以修改，默认是1M，测试时修改为8M。
- 事务需要控制大小，事务太大可能会影响执行的效率。MySQL有innodb_log_buffer_size配置项，超过这个值会把innodb的数据刷到磁盘中，这时，效率会有所下降。所以比较好的做法是，在数据达到这个这个值前进行事务提交。

##MySQL Innodb日志机制深入分析
1.1. Log & Checkpoint
Innodb的事务日志是指Redo log，简称Log,保存在日志文件ib_logfile*里面。Innodb还有另外一个日志Undo log，但Undo log是存放在共享表空间里面的（ibdata*文件）。

由于Log和Checkpoint紧密相关，因此将这两部分合在一起分析。

名词解释：LSN，日志序列号，Innodb的日志序列号是一个64位的整型。

1.1.1. 写入机制
1.1.1.1. Log写入
LSN实际上对应日志文件的偏移量，新的LSN＝旧的LSN + 写入的日志大小。举例如下：

LSN＝1G，日志文件大小总共为600M，本次写入512字节，则实际写入操作为：

l 求出偏移量：由于LSN数值远大于日志文件大小，因此通过取余方式，得到偏移量为400M；

l 写入日志：找到偏移400M的位置，写入512字节日志内容，下一个事务的LSN就是1000000512；

1.1.1.2. Checkpoint写入
Innodb实现了Fuzzy Checkpoint的机制，每次取到最老的脏页，然后确保此脏页对应的LSN之前的LSN都已经写入日志文件，再将此脏页的LSN作为Checkpoint点记录到日志文件，意思就是“此LSN之前的LSN对应的日志和数据都已经写入磁盘文件”。恢复数据文件的时候，Innodb扫描日志文件，当发现LSN小于Checkpoint对应的LSN，就认为恢复已经完成。

Checkpoint写入的位置在日志文件开头固定的偏移量处，即每次写Checkpoint都覆盖之前的Checkpoint信息。

1.1.2. 管理机制
由于Checkpoint和日志紧密相关，将日志和Checkpoint一起说明，详细的实现机制如下：
<img src="日志周期.gif.png" />

Innodb的一条事务日志共经历4个阶段：

1） 创建阶段：事务创建一条日志；

2）日志刷盘：日志写入到磁盘上的日志文件；

3） 数据刷盘：日志对应的脏页数据写入到磁盘上的数据文件；

4）写CKP：日志被当作Checkpoint写入日志文件；

对应这4个阶段，系统记录了4个日志相关的信息，用于其它各种处理使用：

Log sequence number（LSN1）：当前系统LSN最大值，新的事务日志LSN将在此基础上生成（LSN1+新日志的大小）；

Log flushed up to（LSN2）：当前已经写入日志文件的LSN；

Oldest modified data log（LSN3）：当前最旧的脏页数据对应的LSN，写Checkpoint的时候直接将此LSN写入到日志文件；

Last checkpoint at（LSN4）：当前已经写入Checkpoint的LSN；

对于系统来说，以上4个LSN是递减的，即： LSN1>=LSN2>=LSN3>=LSN4.

具体的样例如下（使用show innodb status \G命令查看，Oldest modified data log没有显示）：
<pre>
---
LOG
---
Log sequence number 23 2605355359
Log flushed up to 23 2604861304
Last checkedpoint at 23 1990097397
0 pending log writes, 0 pending chkp writes
1276082 log i/o`s done,6814.09 log i/o`s/second
</pre>
1.1.3. 保护机制
Innodb的数据并不是实时写盘的，为了避免宕机时数据丢失，保证数据的ACID属性，Innodb至少要保证数据对应的日志不能丢失。对于不同的情况，Innodb采取不同的对策：

1）宕机导致日志丢失
Innodb有日志刷盘机制，可以通过innodb_flush_log_at_trx_commit参数进行控制；

2）日志覆盖导致日志丢失

Innodb日志文件大小是固定的，写入的时候通过取余来计算偏移量，这样存在两个LSN写入到同一位置的可能，后面写的把前面写得就覆盖了，以“写入机制”章节的样例为例，LSN＝100000000和LSN＝1600000000两个日志的偏移量是相同的了。这种情况下，为了保证数据一致性，必须要求LSN=1000000000对应的脏页数据都已经刷到磁盘中，也就是要求Last checkpoint对应的LSN一定要大于1000000000，否则覆盖后日志也没有了，数据也没有刷盘，一旦宕机，数据就丢失了。

为了解决第二种情况导致数据丢失的问题，Innodb实现了一套日志保护机制，详细实现如下：

--------------------------------------------------------------------------
->Ckp age ->Buf age ->Buf async->Buf sync->Ckp async->Ckp sync
--------------------------------------------------------------------------

上图中，直线代表日志空间（Log cap，约等于日志文件总大小*0.8，0.8是一个安全系数)，Ckp age和Buf age是两个浮动的点，Buf async、Buf sync、Ckp async、Ckp sync是几个固定的点。各个概念的含义如下：

----------

概念；计算；含义

Ckp age;LSN1- LSN4;还没有做Checkpoint的日志范围，若Ckp age超过日志空间，说明被覆盖的日志（LSN1－LSN4－Log cap）对应日志和数据“可能”还没有刷到磁盘上

Buf age；LSN1- LSN3；还没有将脏页刷盘的日志的范围，若Buf age超过日志空间，说明被覆盖的日志（LSN1－LSN3－Log cap）对应数据“肯定”还没有刷到磁盘上

Buf async；日志空间大小 * 7/8；强制将Buf age-Buf async的脏页刷盘，此时事务还可以继续执行，所以为async，对事务的执行速度没有直接影响（有间接影响，例如CPU和磁盘更忙了，事务的执行速度可能受到影响）

Buf sync;日志空间大小 * 15/16；强制将2*(Buf age-Buf async)的脏页刷盘，此时事务停止执行，所以为sync，由于有大量的脏页刷盘，因此阻塞的时间比Ckp sync要长。

Ckp async;日志空间大小 * 31/32;强制写Checkpoint，此时事务还可以继续执行，所以为async，对事务的执行速度没有影响（间接影响也不大，因为写Checkpoint的操作比较简单）

Ckp sync;日志空间大小 * 64/64;强制写Checkpoint，此时事务停止执行，所以为sync，但由于写Checkpoint的操作比较简单，即使阻塞，时间也很短

----------

当事务执行速度大于脏页刷盘速度时，Ckp age和Buf age会逐步增长，当达到async点的时候，强制进行脏页刷盘或者写Checkpoint，如果这样做还是赶不上事务执行的速度，则为了避免数据丢失，到达sync点的时候，会阻塞其它所有的事务，专门进行脏页刷盘或者写Checkpoint。

因此从理论上来说,只要事务执行速度大于脏页刷盘速度，最终都会触发日志保护机制，进而将事务阻塞，导致MySQL操作挂起。

由于写Checkpoint本身的操作相比写脏页要简单，耗费时间也要少得多，且Ckp sync点在Buf sync点之后，因此绝大部分的阻塞都是阻塞在了Buf sync点，这也是当事务阻塞的时候，IO很高的原因，因为这个时候在不断的刷脏页数据到磁盘。

##MySQL Innodb数据库性能实践——VARCHAR vs CHAR
学过数据库理论的读者，都应该还记得关于CHAR和VARCHAR的性能对比：CHAR比VARCHAR更快，因为CHAR是固定长度的，而VARCHAR需要增加一个长度标识，处理时需要多一次运算。

【总结】
基于额外的测试结果和分析，我个人认为一般情况下优先使用VARCHAR，特别是字符串的平均长度比最大长度要小很多的情况；当然，如果你的字符串本来就很短，例如只有10个字符，那么就优先选CHAR了。

##MySQL Sending data导致查询很慢的问题详细分析
【问题现象】

使用sphinx支持倒排索引，但sphinx从mysql查询源数据的时候，查询的记录数才几万条，但查询的速度非常慢，大概要4~5分钟左右

【处理过程】

- explain

首先怀疑索引没有建好，于是使用explain查看查询计划。

- show processlist;

explain看不出问题，那到底慢在哪里呢？
于是想到了使用 show processlist查看sql语句执行状态，查询结果如下：
<pre>
Id:459
User:mng
Host:127.0.0.1:45619
db:nanagement
Command:Query
Time:15
State:Sending data
Into:SELECT gp.id id,gp.platform_id platform_id,gp.game_id game_id,g.category_ud category_id,gt.paren
</pre>
发现很长一段时间，查询都处在 “Sending data”状态;查询一下“Sending data”状态的含义，原来这个状态的名称很具有误导性，所谓的“Sending data”并不是单纯的发送数据，而是包括“收集 + 发送 数据”。

这里的关键是为什么要收集数据，原因在于：mysql使用“索引”完成查询结束后，mysql得到了一堆的行id，如果有的列并不在索引中，mysql需要重新到“数据行”上将需要返回的数据读取出来返回个客户端。

- show profile

为了进一步验证查询的时间分布，于是使用了show profile命令来查看详细的时间分布
<b>首先打开配置：set profiling=on;
执行完查询后，使用show profiles查看query id;
使用show profile for query query_id查看详细信息</b>;

从结果可以看出，Sending data的状态执行了216s

- 排查对比
- 
经过以上步骤，已经确定查询慢是因为大量的时间耗费在了Sending data状态上，结合Sending data的定义，将目标聚焦在查询语句的返回列上面.

经过一 一排查，最后定为到一个description的列上，这个列的设计为：
<pre>
`description`varchar(8000) DEFAULT NULL COMMENT '游戏描述',
</pre>
于是采取了对比的方法，看看“不返回description的结果”如何。show profile的结果如下：

可以看出，不返回description的时候，查询时间只需要15s，返回的时候，需要216s，两者相差15倍

【原理研究】

一篇淘宝的文章很好的解释了相关原理：innodb使用大字段text，blob的一些优化建议
这里的关键信息是：<b>当Innodb的存储格式是 ROW_FORMAT=COMPACT (or ROW_FORMAT=REDUNDANT)的时候，Innodb只会存储前768字节的长度，剩余的数据存放到“溢出页”中</b>。
我们使用show table status来查看表的相关信息。从表的信息可以看到，平均一行大约1.5K，也就说大约1/10行会使用“溢出存储”，一旦采用了这种方式存储，返回数据的时候<b>本来是顺序读取的数据，就变成了随机读取</b>了，所以导致性能急剧下降。

另外，在测试过程中还发现，无论这条语句执行多少次，甚至将整个表select *几次，语句的执行速度都没有明显变化。这个表的数据和索引加起来才150M左右，而整个Innodb buffer pool有5G，缓存整张表绰绰有余，如果缓存了溢出页，性能应该大幅提高才对。<br>
但实测结果却并没有提高，因此从这个测试可以推论<b>Innodb并没有将溢出页（overflow page）缓存到内存里面</b>。<br>
这样的设计也是符合逻辑的，因为overflow page本来就是存放大数据的，如果也放在缓存里面，就会出现一次大数据列（blob、text、varchar）查询，可能就将所有的缓存都更新了，这样会导致其它普通的查询性能急剧下降。

【解决方法】

找到了问题的根本原因，解决方法也就不难了。有几种方法：

- 查询时去掉description的查询，但这受限于业务的实现，可能需要业务做较大调整
- 表结构优化，将descripion拆分到另外的表，这个改动较大，需要已有业务配合修改，且如果业务还是要继续查询这个description的信息，则优化后的性能也不会有很大提升。


##MySQL乱码问题
【乱码的产生】

答案其实很简单：<b>“转换导致乱码”</b>！根据这个原则来判断，各种情况就很简单了：

- 数据传送过程中不会导致乱码
- 数据存储不会导致乱码
- 数据输入和输出（包括显示）可能导致乱码
- 数据接收和发送可能导致乱码

更详细的解释：转换导致乱码是指本来是A字符集的数据被当成了B字符集进行解析，而不是说正确的A字符集转换为B字符集。<br>
例如：如下mysql字符处理机制流程图中，mysql客户端发送的实际上是2个gbk字符（4字节），但character_set_connection
设置了utf8，于是mysql服务器将收到的4字节gbk数据按照utf8解析，得到1个中文字符+1个字节，这时就产生乱码了；如果character_set_connection 设置为gbk，mysql服务器收到数据后按照gbk解析，得到两个正确的中文，然后再转换为这两个中文对应的utf8编码，这就不会产生乱码。）

我们模拟一下一条数据从插入到读取的处理流程，看看在整个流程中，字符集是如何辗转腾挪的。
【插入流程】
<pre>
1. 客户端设定了自己的编码（character_set_client），接收用户的输入；
2. 客户端将用户的输入“转换”成连接的编码（character_set_connection） =====> 第一次转换
3. 客户端将转换后的数据发送给服务器；                               =====> 传输不会导致编码转换
4. 服务器收到客户端的数据，再判断数据列的字符集，进行字符转换       =====> 第二次转换
5. 服务器将数据存储（例如磁盘）                                     =====> 存储不会导致编码转换
</pre>  
【读取流程】
<pre>
略去前面的sql语句处理流程，从数据读取开始
1. 服务器从存储（例如磁盘）读取数据                                 =====> 存储不会导致编码转换，因此从存储读取也不需要
2. 服务器判断当前连接返回结果的字符集（character_set_results），
   将读取的数据转换为结果集要求的数据                               =====> 逆向的第一次转换，对应正向的第二次编码转换
3. 服务器将数据发送给客户端                                         =====> 传输不会导致编码转换
4. 客户端收到服务器的数据，根据客户端的字符集（character_set_client）进行编码转换          =====> 逆向第二次转换，对应正向第一次编码转换
5. 客户端显示数据                                                   =====> 你能看到乱码的时候
</pre>
有了这个流程，我们就很容易定位乱码可能产生的地方，以及产生乱码的字符集配置究竟是哪个了。理想的情况是整个流程中，所有涉及字符转换的地方都不需要转换，这样就不会产生乱码了。
###mysql字符编码操作技巧
【查看字符集设置】
<pre>
mysql> show variables like '%char%';
+--------------------------+-----------------------------------------------------+
| Variable_name            | 说明                                                |
+--------------------------+-----------------------------------------------------+
| character_set_client     | 客户端字符集                                        |
| character_set_connection | 当前连接字符集                                      |
| character_set_database   | 数据库字符集                                        |
| character_set_filesystem | 文件系统字符集，不要修改，使用binary即可            |
| character_set_results    | 返回结果集字符集                                    |
| character_set_server     | 服务器默认字符集，当数据库、表、列没有设置时，      |
|                          |     默认使用此字符集                                |
| character_set_system     | 固定为utf8                                          |
+--------------------------+-----------------------------------------------------+
 </pre>
【修改字符集设置】

服务器的配置在服务器建立的时候就由DBA设置好了，不推荐后续再改
通过SET NAMES utf8命令同时设置character_set_client/character_set_connection/character_set_results的字符集
建议所有配置都设置成utf8

【问题答案】

- 思考一下1：为什么客户端和连接都设置了latin1，但最终发送的是正确的utf8编码呢？<br>
客户端设置了latin1，而我的语句是从notepad++中写好的，是utf8格式的；
中文utf8是3个字节，而latin1是按照单个字节解析的，虽然进行了转换，但不会导致二进制内容的变化，但实际上mysql客户端认为我输入了3个latin1字符；
如果客户端设置的编码是2个字节的gbk，这时转换就会发生乱码，utf8的3个字节会被转换为1个gbk字符（可能是乱码，也可能不是乱码）加上一个西欧字符（小于128就是英文，大于128就是其它西欧文）.

- 思考一下2：为什么接收到的还是正确的utf8编码？<br>
这是因为mysql服务器从将数据从“列”的编码（utf8）转换为latin1了，而列存储的数据并不是真正的utf8的中文“你”对应的"0xe4 0xbd 0xa0"，
而是后面抓包看到的“c3a4 c2bd c2a0”（6个字节），mysql服务器将utf8的c3a4转换为latin1的0xe4，c2bd转换为0xbd, c2a0转换为0xa0

- 思考一下3：为什么latin1显示了正确的utf8字符？<br>
因为mysql客户端收到了mysql服务器转换后的"0xe4 0xbd 0xa0"，并把这个数据当做latin1的3个字符处理，然后抛给终端（我的是SecureCRT），
SecureCRT又把这三个latin1当做uft8处理，结果中文的“你”就显示出来了。

- 思考一下4：为什么连接的字符集和数据库的字符集设置成一样了，接收的数据反而不是utf8了？（请与latin1接收数据包对比）<br>
字符集都一样的情况下，整个流程中不需要进行编码转换，直接将存储的“c3a4 c2bd c2a0”返回给客户端

- 思考一下5：为什么连接的字符集和数据库的字符集设置成一样了，显示反而乱码了？<br>
参考思考4，客户端收到数据后也直接抛给终端显示，终端认为是两个utf8字符，并且找到了对应字符并显示，但我们看不懂，所以知道是乱码了，但这两个字符显示并没有错，如果真正找不到字符，可能会显示问号或者字符集规定的缺省符号.

##MySQL Innodb数据库性能实践——热点数据性能
对于大部分的应用来说，都存在热点数据的访问，即：某些数据在一定时间内的访问频率要远远高于其它数据。<br>
常见的热点数据有“最新的新闻”、“最热门的新闻”、“下载量最大”的电影等。

下面是MySQL Innodb对热点数据支持的总结方法。

【总结】

Innodb buffer pool采用LRU的方式管理和淘汰数据，根据LRU算法，热点数据都会优先放入内存，因此热点数据的测试性能比随机访问的要高出不少。
但热点数据超出Innodb buffer pool后，磁盘IO成为性能主要瓶颈，性能会急剧下降。

【应用建议】

实际应用中涉及热点数据访问时，Innodb是一个高性能的较好的选择，但前提是要能够预估热点数据的大小，只有当热点数据小于Innodb buffer pool（即热点数据全部能够放入内存）时，才能够获得高性能。
##MySQL Innodb数据库性能实践——合适的表记录数
【问题】

MySQL Innodb表记录数多大是合适的？<br>
一般的理解肯定是表越大性能越低，但具体低多少呢，是缓慢下降还是急剧下降，是1000万就下降还是1亿才下降呢？

【验证分析】

分析如下：

- 当表大小小于Inndob buffer pool时，整体性能会随着表记录数的增加而略微降低，但各种操作的性能差别总体不大（例如1KW/2KW是12000TPS，5KW是10000TPS，相差16%）。
- 当表大小大于Innodb buffer pool（10KW）时，性能急剧下降（从12000降到1000），性能接近高安全性配置的性能，因为此时磁盘IO成为了性能的主要影响因素。

【实验结论】

因此，表记录数本身对性能影响不大，关键是表的大小是否小于Innodb buffer pool。

额外得出的结论：

相比表记录数来说，行长度对性能影响更大，行越长性能越低。

【应用建议】

基于以上分析，对于表记录数需要考虑的是记录数的临界点，即：表达到这个记录数后，表大小（数据和索引）超过了Innodb buffer pool的大小；而设计时推荐尽量设计和试用行长度小而精的表。

##异步
异步的概念和同步相对。

与同步相对应，异步指的是让CPU暂时搁置当前请求的响应,处理下一个请求,当通过轮询或其他方式得到回调通知后,开始运行。多线程将异步操作放入另一线程中运行，通过轮询或回调方法得到完成通知,但是完成端口，由操作系统接管异步操作的调度，通过硬件中断，在完成时触发回调方法，此方式不需要占用额外线程。

###异步通信
在通信中，“异步通信”是一种很常用的通信方式。异步通信在发送字符时，所发送的字符之间的时间间隔可以是任意的。当然，接收端必须时刻做好接收的准备（如果接收端主机的电源都没有加上，那么发送端发送字符就没有意义，因为接收端根本无法接收）。发送端可以在任意时刻开始发送字符，因此必须在每一个字符的开始和结束的地方加上标志，即加上开始位和停止位，以便使接收端能够正确地将每一个字符接收下来。异步通信的好处是通信设备简单、便宜，但传输效率较低（因为开始位和停止位的开销所占比例较大）。

异步通信也可以是以帧作为发送的单位。接收端必须随时做好接收帧的准备。这时，帧的首部必须设有一些特殊的比特组合，使得接收端能够找出一帧的开始。这也称为帧定界。帧定界还包含确定帧的结束位置。这有两种方法。一种是在帧的尾部设有某种特殊的比特组合来标志帧的结束。或者在帧首部中设有帧长度的字段。需要注意的是，在异步发送帧时，并不是说发送端对帧中的每一个字符都必须加上开始位和停止位后再发送出去，而是说，发送端可以在任意时间发送一个帧，而帧与帧之间的时间间隔也可以是任意的。在一帧中的所有比特是连续发送的。发送端不需要在发送一帧之前和接收端进行协调（不需要先进行比特同步）。

- 异步操作的本质

所有的程序最终都会由计算机硬件来执行，所以为了更好的理解异步操作的本质，我们有必要了解一下它的硬件基础。 熟悉电脑硬件的朋友肯定对DMA这个词不陌生，硬盘、光驱的技术规格中都有明确DMA的模式指标，其实网卡、声卡、显卡也是有DMA功能的。DMA就是直 接内存访问的意思，也就是说，拥有DMA功能的硬件在和内存进行数据交换的时候可以不消耗CPU资源。只要CPU在发起数据传输时发送一个指令，硬件就开 始自己和内存交换数据，在传输完成之后硬件会触发一个中断来通知操作完成。这些无须消耗CPU时间的I/O操作正是异步操作的硬件基础。所以即使在DOS 这样的单进程（而且无线程概念）系统中也同样可以发起异步的DMA操作。

- 线程的本质

线程不是一个计算机硬件的功能，而是操作系统提供的一种逻辑功能，线程本质上是进程中一段并发运行的代码，所以线程需要操作系统投入CPU资源来运行和调度。

- 异步操作的优缺点

因为异步操作无须额外的线程负担，并且使用回调的方式进行处理，在设计良好的情况下，处理函数可以不必使用共享变量（即使无法完全不用，最起码可以减少 共享变量的数量），减少了死锁的可能。当然异步操作也并非完美无暇。编写异步操作的复杂程度较高，程序主要使用回调方式进行处理，与普通人的思维方式有些出入，而且难以调试。

- 多线程的优缺点

多线程的优点很明显，线程中的处理程序依然是顺序执行，符合普通人的思维习惯，所以编程简单。但是多线程的缺点也同样明显，线程的使用（滥用）会给系统带来上下文切换的额外负担。并且线程间的共享变量可能造成死锁的出现。

- 适用范围

在了解了线程与异步操作各自的优缺点之后，我们可以来探讨一下线程和异步的合理用途。我认为：当需要执行I/O操作时，使用异步操作比使用线程+同步 I/O操作更合适。I/O操作不仅包括了直接的文件、网络的读写，还包括数据库操作、Web Service、HttpRequest以及.net Remoting等跨进程的调用。

而线程的适用范围则是那种需要长时间CPU运算的场合，例如耗时较长的图形处理和算法执行。但是往往由于使用线程编程的简单和符合习惯，所以很多朋友往往会使用线程来执行耗时较长的I/O操作。这样在只有少数几个并发操作的时候还无伤大雅，如果需要处理大量的并发操作时就不合适了。

