++++Centos下搭建FTP上传下载服务器++++
1、首先判断你服务器上是否安装了vsftpd
rpm -q vsftpd
2、安装完成之后就要重启vsftpd服务
service vsftpd restart
3、到vsftpd的主配置文件里面
vi /etc/vsftpd/vsftpd.conf
anonymous_enable=NO
把这个改为NO 默认是YES （改为NO 就是禁止匿名用户登录，不需要注释）
不可以让ftp用户跳出自己的家目录，否则太危险了。需要做限制
chroot_local_user=YES
默认是注释掉的，把#号去掉  然后重启vsftpd
4、创建ftp用户
useradd -s /sbin/nologin -d /var/www/XXXX(指定文件名） admin（自定义用户名）
（admin这个用户智能连接ftp无法登录系统，默认家目录在/var/www/XXXX  文件夹下面）
5、给admin这个用户设置密码
passwd admin
6、然后给家目录文件修改权限，否则你无法你无法上传文件
chmod o+w /var/www/XXXX
7、然后修改selinux
（查看selinux状态：/usr/sbin/sestatus -v 或 getenforce）
修改文件/etc/selinux/config  文件
将SELINUX=enforcing改为SELINUX=disabled
重启机器即可
8、重启vsftpd服务，并且下次自动启动
service vsftpd restart
9、关闭防火墙
service iptables stop



++++服务器维护中常用dos命令+++++
1.ping命令
用法：ping+空格+域名
作用：ping命令可以用来检查网络是否通畅、域名解析是正否正确以及是否丢包等等，而在服务器维护
中ping命令是第一个必须掌握的DOS命令。
2.telnet命令
用法：telnet+空格+域名+端口号 （默认情况IIS的端口号是80,Apache的端口号是8080）
作用：测试服务器端口是否连通。
3.tracert命令(路由跟踪)
用法：tracert+空格+域名
作用：网络是一个节点连接一个节点，而每个节点都有路由，通过tracert命令可以知道自己家到服务器
所在机房有多少节点，以及知道每个节点是否通畅。（一般情况节点越少，服务器打开越快）


+++++Linux系统查看和修改IP的方法++++++
1.显示当前启动的网络接口命令:
ifconfig
2.查看当前所有网络接口命令:
ifconfig -a
3.查看指定网络接口命令:
ifconfig eth0
在LINUX下修改IP分为二种情况
1.调试时修改IP,仅在当前生效,重启后恢复为原有IP
ifconfig eth0 192.168.63.27 netmask 255.255.255.0 route add default gw 192.168.63.1 up
2.永久生效(即重启后也能生效)
方法1:配置网卡的配置文件 
修改/etc/sysconfig/network-scripts/ifcfg-eth0
然后重启服务service network restart生效,或者/etc/init.d/network restart生效
方法2:
将ifconfig eth0 192.168.63.27 netmask 255.255.255.0 route add default gw 192.168.63.1 保存在/etc/init.d/rc.local文件中

数据库注意事项
mysql_free_result($result);关闭结果集
mysql_close($link);关闭与数据库的连接


+++++ab工具检测apache服务器性能+++++
cmd切入到ab.exe目录下，ab -n 5000 -c 247 http://localhost/test.php     //模拟5000次访问量，247同时在线（并发）
-t测试进行总时间，单位是秒，默认50000s，-p post时的数据文件，-w以HTML表的格式输出结果



+++并行技术++++
共享内存：所有CPU共内存，所有CPU由一个操作系统控制的，例如Windows和Linux/UNIX，目前流行的多核、多CPU机器都是属于这种；

消息驱动：其实就是分布式内存，CPU由不同的操作系统控制，不同的CPU之间通过网络通信。例如网格Grid是通过因特网通信、集群Cluster是通过局域网通信、MPP是通过专有的高速网络通信。

通过上面的对比，聪明的读者估计很快就想到了这两种系统并行程序实现方式的差异：

共享内存：通过操作系统的多进程多线程来完成并行任务，通过进程间通信来完成协作；

消息驱动：通过多台机器来完成并行任务，通过消息来完成协作。(MPP物理上看是一台机器，逻辑上是多台机器)。

当然，由于消息驱动系统中每个处理单元都是一台独立的机器，对这台独立的机器本身当然也可以通过共享内存来实现并行处理。

 

嗯，非常不错，经过我们的层层分析和筛选，原来各种各样的看起来很吓人的并行系统，最终被我们归纳总结出两种并行实现技术：多进程多线程、多机协作。


++++http500错误++++
Internal Server Error 解决办法：
如果你想解决PHP程序中的文件权限设置错误，并且不造成网站发生500内部服务器错误。那么需要依循以下规则：
1.保证：文件夹权限要设置为755或者更低,文件权限要设置为644或者更低。
2.如果文件权限是644但是PHP程序功能还是不好用，提示文件权限不够，那么可以联系客服，让他们将安全模块禁用。

++常见状态码++++
 static $_status = array(
        // Success 2xx
        200 => 'OK',
        // Redirection 3xx
        301 => 'Moved Permanently',  //永久移除
        302 => 'Moved Temporarily ',  // 1.1 暂时移除
        // Client Error 4xx
        400 => 'Bad Request',  //请求无效
        403 => 'Forbidden',    //禁止访问
        404 => 'Not Found',     //没有找到
        // Server Error 5xx
        500 => 'Internal Server Error',   //网络文件权限错误
        503 => 'Service Unavailable',  //服务不可用,可能是一个网站的程序占资源太多或者发生太多的错误
    );



+++数据链路层的基本知识 ++++
数据链路层的作用：1、IP数据模块发送和接收IP数据报；2、为ARP模块发送ARP请求和接收ARP协议；3、为RARP发送RARP请求
和接受RARP应答。
数据链路层使用的信道主要有一下两种类型：
点对点信道：这种信道的通信方式是一对一的通信方式----------ppp协议
广播信道：这种信道使用一对多的广播通信方式，对于这种方式需要遵循专用的共享信道协议来协调主机数据的发送；
链路：即使从一个结点到相邻结点的一段物理线路。而中间没有任何其他的交换结点。又称 为：物理链路
数据链路：因为当需要在一条线路上传递数据时，除了必须使用一条物理设备时，还需要一些必要的通信协议来控制数据
的传输，若把实现这些协议的硬件和软件的加到链路上，就叫做数据链路；最常用的是-----网络适配器。一般适配器都
包含了数据链路层和物理层这两层的功能----又称为逻辑链路。

+++TCP粘包和拆包问题+++++
问题产生
一个完整的业务可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这个就是TCP的拆包和封包问题。
下面可以看一张图，是客户端向服务端发送包：
1. 第一种情况，Data1和Data2都分开发送到了Server端，没有产生粘包和拆包的情况。
2. 第二种情况，Data1和Data2数据粘在了一起，打成了一个大的包发送到Server端，这个情况就是粘包。
3. 第三种情况，Data2被分离成Data2_1和Data2_2，并且Data2_1在Data1之前到达了服务端，这种情况就产生了拆包。
由于网络的复杂性，可能数据会被分离成N多个复杂的拆包/粘包的情况，所以在做TCP服务器的时候就需要首先解决拆包/粘包的问题。

TCP粘包和拆包产生的原因
1. 应用程序写入数据的字节大小大于套接字发送缓冲区的大小
2. 进行MSS大小的TCP分段。MSS是最大报文段长度的缩写。MSS是TCP报文段中的数据字段的最大长度。数据字段加上TCP首部才等于整个的TCP报文段。所以MSS并不是TCP报文段的最大长度，而是：MSS=TCP报文段长度-TCP首部长度
3. 以太网的payload大于MTU进行IP分片。MTU指：一种通信协议的某一层上面所能通过的最大数据包大小。如果IP层有一个数据包要传，而且数据的长度比链路层的MTU大，那么IP层就会进行分片，把数据包分成托干片，让每一片都不超过MTU。注意，IP分片可以发生在原始发送端主机上，也可以发生在中间路由器上。

TCP粘包和拆包的解决策略
1. 消息定长。例如100字节。
2. 在包尾部增加回车或者空格符等特殊字符进行分割，典型的如FTP协议
3. 将消息分为消息头和消息尾。
4. 其它复杂的协议，如RTMP协议等。

++++网络IO模型++++
网络IO模型介绍
常见的IO模型有以下5种：
1. 阻塞式IO （blocking IO）
2.无阻塞式IO （nonblocking IO）
3.IO多路复用 （IO multiplexing）
4. 信号驱动 （signal driven IO）
5. 异步IO （asynchronous IO）

阻塞式IO （blocking IO）
在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：
当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来.
    所以，blocking IO的特点就是在IO执行的两个阶段（等待数据和拷贝数据两个阶段）都被block了。
 所以，blocking IO的特点就是在IO执行的两个阶段（等待数据和拷贝数据两个阶段）都被block了。
    几乎所有的程序员第一次接触到的网络编程都是从listen()、send()、recv() 等接口开始的，这些接口都是阻塞型的。使用这些接口可以很方便的构建服务器/客户机的模型。下面是一个简单地“一问一答”的服务器。
 我们注意到，大部分的socket接口都是阻塞型的。所谓阻塞型接口是指系统调用（一般是IO接口）不返回调用结果并让当前线程一直阻塞，只有当该系统调用获得结果或者超时出错时才返回。
    实际上，除非特别指定，几乎所有的IO接口 ( 包括socket接口 ) 都是阻塞型的。这给网络编程带来了一个很大的问题，如在调用send()的同时，线程将被阻塞，在此期间，线程将无法执行任何运算或响应任何的网络请求。
 一个简单的改进方案是在服务器端使用多线程（或多进程）。多线程（或多进程）的目的是让每个连接都拥有独立的线程（或进程），这样任何一个连接的阻塞都不会影响其他的连接。具体使用多进程还是多线程，并没有一个特定的模式。传统意义上，进程的开销要远远大于线程，所以如果需要同时为较多的客户机提供服务，则不推荐使用多进程；如果单个服务执行体需要消耗较多的CPU资源，譬如需要进行大规模或长时间的数据运算或文件访问，则进程较为安全。通常，使用pthread_create ()创建新线程，fork()创建新进程。
    我们假设对上述的服务器 / 客户机模型，提出更高的要求，即让服务器同时为多个客户机提供一问一答的服务。于是有了如下的模型。
在上述的线程 / 时间图例中，主线程持续等待客户端的连接请求，如果有连接，则创建新线程，并在新线程中提供为前例同样的问答服务。
    很多初学者可能不明白为何一个socket可以accept多次。实际上socket的设计者可能特意为多客户机的情况留下了伏笔，让accept()能够返回一个新的socket。下面是 accept 接口的原型：
     int accept(int s, struct sockaddr *addr, socklen_t *addrlen);
    输入参数s是从socket()，bind()和listen()中沿用下来的socket句柄值。执行完bind()和listen()后，操作系统已经开始在指定的端口处监听所有的连接请求，如果有请求，则将该连接请求加入请求队列。调用accept()接口正是从 socket s 的请求队列抽取第一个连接信息，创建一个与s同类的新的socket返回句柄。新的socket句柄即是后续read()和recv()的输入参数。如果请求队列当前没有请求，则accept() 将进入阻塞状态直到有请求进入队列。
    上述多线程的服务器模型似乎完美的解决了为多个客户机提供问答服务的要求，但其实并不尽然。如果要同时响应成百上千路的连接请求，则无论多线程还是多进程都会严重占据系统资源，降低系统对外界响应效率，而线程与进程本身也更容易进入假死状态。

    很多程序员可能会考虑使用“线程池”或“连接池”。“线程池”旨在减少创建和销毁线程的频率，其维持一定合理数量的线程，并让空闲的线程重新承担新的执行任务。“连接池”维持连接的缓存池，尽量重用已有的连接、减少创建和关闭连接的频率。这两种技术都可以很好的降低系统开销，都被广泛应用很多大型系统，如websphere、tomcat和各种数据库等。但是，“线程池”和“连接池”技术也只是在一定程度上缓解了频繁调用IO接口带来的资源占用。而且，所谓“池”始终有其上限，当请求大大超过上限时，“池”构成的系统对外界的响应并不比没有池的时候效果好多少。所以使用“池”必须考虑其面临的响应规模，并根据响应规模调整“池”的大小。
    对应上例中的所面临的可能同时出现的上千甚至上万次的客户端请求，“线程池”或“连接池”或许可以缓解部分压力，但是不能解决所有问题。总之，多线程模型可以方便高效的解决小规模的服务请求，但面对大规模的服务请求，多线程模型也会遇到瓶颈，可以用非阻塞接口来尝试解决这个问题。

无阻塞式IO （nonblocking IO）
当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。
    所以，在非阻塞式IO中，用户进程其实是需要不断的主动询问kernel数据准备好了没有。
 可以看到服务器线程可以通过循环调用recv()接口，可以在单个线程内实现对所有连接的数据接收工作。但是上述模型绝不被推荐。因为，循环调用recv()将大幅度推高CPU 占用率；此外，在这个方案中recv()更多的是起到检测“操作是否完成”的作用，实际操作系统提供了更为高效的检测“操作是否完成“作用的接口，例如select()多路复用模式，可以一次检测多个连接是否活跃。

IO多路复用 （IO multiplexing）
IO multiplexing这个词可能有点陌生，但是如果我说select/epoll，大概就都能明白了。有些地方也称这种IO方式为事件驱动IO(event driven IO)。我们都知道，select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。
当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。
    这个图和blocking IO的图其实并没有太大的不同，事实上还更差一些。因为这里需要使用两个系统调用(select和recvfrom)，而blocking IO只调用了一个系统调用(recvfrom)。但是，用select的优势在于它可以同时处理多个connection。（多说一句：所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）
    在多路复用模型中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。因此select()与非阻塞IO类似。

    大部分Unix/Linux都支持select函数，该函数用于探测多个文件句柄的状态变化。下面给出select接口的原型：
    FD_ZERO(int fd, fd_set* fds)
    FD_SET(int fd, fd_set* fds)
    FD_ISSET(int fd, fd_set* fds)
    FD_CLR(int fd, fd_set* fds)
    int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds,
    struct timeval *timeout)

    这里，fd_set 类型可以简单的理解为按 bit 位标记句柄的队列，例如要在某 fd_set 中标记一个值为16的句柄，则该fd_set的第16个bit位被标记为1。具体的置位、验证可使用 FD_SET、FD_ISSET等宏实现。在select()函数中，readfds、writefds和exceptfds同时作为输入参数和输出参数。如果输入的readfds标记了16号句柄，则select()将检测16号句柄是否可读。在select()返回后，可以通过检查readfds有否标记16号句柄，来判断该“可读”事件是否发生。另外，用户可以设置timeout时间。
 但这个模型依旧有着很多问题。首先select()接口并不是实现“事件驱动”的最好选择。因为当需要探测的句柄值较大时，select()接口本身需要消耗大量时间去轮询各个句柄。很多操作系统提供了更为高效的接口，如linux提供了epoll，BSD提供了kqueue，Solaris提供了/dev/poll，…。如果需要实现更高效的服务器程序，类似epoll这样的接口更被推荐。遗憾的是不同的操作系统特供的epoll接口有很大差异，所以使用类似于epoll的接口实现具有较好跨平台能力的服务器会比较困难。
    其次，该模型将事件探测和事件响应夹杂在一起，一旦事件响应的执行体庞大，则对整个模型是灾难性的。如下例，庞大的执行体1的将直接导致响应事件2的执行体迟迟得不到执行，并在很大程度上降低了事件探测的及时性。

异步IO （asynchronous IO）
用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。

    用异步IO实现的服务器这里就不举例了，以后有时间另开文章来讲述。异步IO是真正非阻塞的，它不会对请求进程产生任何的阻塞，因此对高并发的网络服务器实现至关重要。
    到目前为止，已经将四个IO模型都介绍完了。现在回过头来回答最初的那几个问题：blocking和non-blocking的区别在哪，synchronous IO和asynchronous IO的区别在哪。
先回答最简单的这个：blocking与non-blocking。前面的介绍中其实已经很明确的说明了这两者的区别。调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还在准备数据的情况下会立刻返回。

    在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。Stevens给出的定义（其实是POSIX的定义）是这样子的：
    * A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;
    * An asynchronous I/O operation does not cause the requesting process to be blocked;
    两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。有人可能会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个系统调用。non-blocking IO在执行recvfrom这个系统调用的时候，如果kernel的数据没有准备好，这时候不会block进程。但是当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内进程是被block的。而asynchronous IO则不一样，当进程发起IO操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。

    还有一种不常用的signal driven IO，即信号驱动IO。总的来说，UNP中总结的IO模型有5种之多：阻塞IO，非阻塞IO，IO复用，信号驱动IO，异步IO。前四种都属于同步IO。阻塞IO不必说了。非阻塞IO ，IO请求时加上O_NONBLOCK一类的标志位，立刻返回，IO没有就绪会返回错误，需要请求进程主动轮询不断发IO请求直到返回正确。IO复用同非阻塞IO本质一样，不过利用了新的select系统调用，由内核来负责本来是请求进程该做的轮询操作。看似比非阻塞IO还多了一个系统调用开销，不过因为可以支持多路IO，才算提高了效率。信号驱动IO，调用sigaltion系统调用，当内核中IO数据就绪时以SIGIO信号通知请求进程，请求进程再把数据从内核读入到用户空间，这一步是阻塞的。
异步IO，如定义所说，不会因为IO操作阻塞，IO操作全部完成才通知请求进程。
  经过上面的介绍，会发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。


+++关于海量数据处理+++++
常用的数据结构：

1.Bloom Filter
   大致思想是这样，把一个数据通过N个哈希函数映射到一个长度为M的数组的一位上，将hash函数对应的值的位数组置1，查找时如果发现所有hash函数对应位都是1说明该数据的存在。但不能保证完全正确性，但是此方法无比高效。

【实例】给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢？ 

2.哈希法
   这个简单，无非是通过一些哈希函数把元素搞到一个指定的位置，简单的说就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。这个很一般啊感觉。无非就是分类查找么，完全不如1猛。

3.最大或最小堆
     就是一个完全的最大或最小二叉树，用途，比如:1)100w个数中找最大的前100个数。 用一个100个元素大小的最小堆即可。感觉还是不错的。

4.Bit-map
所谓的Bit-map就是用一个bit位来标记某个元素对应的Value， 而Key即是该元素。由于采用了Bit为单位来存储数据，因此在存储空间方面，可以大大节省。


实例:公司的一道考试题算法分析――大数据量整数排序
    题目大意：移动公司需要对已经发放的所有139段的号码进行统计排序，已经发放的139号码段的文件都存放在一个文本文件中（原题是放在两个文件中），一个号码一行，现在需要将文件里的所有号码进行排序，并写入到一个新的文件中；号码可能会有很多，最多可能有一亿个不同的号码（所有的139段号码），存入文本文件中大概要占1.2G的空间；jvm最大的内存在300以内，程序要考虑程序的可执行性及效率；只能使用Java标准库，不得使用第三方工具。
    这是个典型的大数据量的排序算法问题，首先要考虑空间问题，一下把1.2G的数据读入内存是不太可能的，就算把1一亿条数据，转都转换成int类型存储也要占接近400M的空间。当时做个题目我并没有想太多的执行效率问题，主要就考虑了空间，而且习惯性的想到合并排序，基本思想是原文件分割成若干个小文件并排序，再将排序好的小文件合并得到最后结果，算法大概如下： 
  1.顺序读取存放号码文件的中所有号码，并取139之后的八位转换为int类型；每读取号码数满一百万个，（这个数据可配置）将已经读取的号码排序并存入新建的临时文件。
    2.将所有生成的号码有序的临时文件合并存入结果文件。
    这个算法虽然解决了空间问题，但是运行效率极低，由于IO读写操作太多，加上步骤1中的排序的算法（快速排序）本来效率就不高（对于电话排序这种特殊情况来说），导致1亿条数据排序运行3个小时才有结果。 

另外一种是：使用是位向量（实际上就是一个bit数组），用电话作为index，心中大喜，找到了解决此问题的最完美方案啦：用位向量存储电话号码，一个号码占一个bit，一亿个电话号码也只需要大概12M的空间；算法大概如下：
      1.初始化bits[capacity]；
      2.顺序所有读入电话号码，并转换为int类型，修改位向量值：bits[phoneNum]=1；
      3.遍历bits数组，如果bits[index]=1，转换index为电话号码输出。 
    Java中没有bit类型，一个boolean值占空间为1byte，这里写个用int模拟bit数组的类：
<pre>
public class BitArray {   
    private int[] bits = null;   
    private int length;   
    //用于设置或者提取int类型的数据的某一位(bit)的值时使用  
    private final static int[] bitValue = {   
        0x80000000,//10000000 00000000 00000000 00000000         
        0x40000000,//01000000 00000000 00000000 00000000         
        0x20000000,//00100000 00000000 00000000 00000000         
        0x10000000,//00010000 00000000 00000000 00000000         
        0x08000000,//00001000 00000000 00000000 00000000         
        0x04000000,//00000100 00000000 00000000 00000000         
        0x02000000,//00000010 00000000 00000000 00000000         
        0x01000000,//00000001 00000000 00000000 00000000         
        0x00800000,//00000000 10000000 00000000 00000000         
        0x00400000,//00000000 01000000 00000000 00000000         
        0x00200000,//00000000 00100000 00000000 00000000         
        0x00100000,//00000000 00010000 00000000 00000000         
        0x00080000,//00000000 00001000 00000000 00000000         
        0x00040000,//00000000 00000100 00000000 00000000         
        0x00020000,//00000000 00000010 00000000 00000000         
        0x00010000,//00000000 00000001 00000000 00000000             
        0x00008000,//00000000 00000000 10000000 00000000         
        0x00004000,//00000000 00000000 01000000 00000000         
        0x00002000,//00000000 00000000 00100000 00000000         
        0x00001000,//00000000 00000000 00010000 00000000         
        0x00000800,//00000000 00000000 00001000 00000000         
        0x00000400,//00000000 00000000 00000100 00000000         
        0x00000200,//00000000 00000000 00000010 00000000         
        0x00000100,//00000000 00000000 00000001 00000000         
        0x00000080,//00000000 00000000 00000000 10000000         
        0x00000040,//00000000 00000000 00000000 01000000         
        0x00000020,//00000000 00000000 00000000 00100000         
        0x00000010,//00000000 00000000 00000000 00010000         
        0x00000008,//00000000 00000000 00000000 00001000         
        0x00000004,//00000000 00000000 00000000 00000100         
        0x00000002,//00000000 00000000 00000000 00000010         
        0x00000001 //00000000 00000000 00000000 00000001               
    };   
    public BitArray(int length) {   
        if(length < 0){   
            throw new IllegalArgumentException("length必须大于零！");   
        }   
        bits = new int[length / 32 + (length % 32 > 0 ? 1 : 0)];   
        this.length = length;   
    }   
    //取index位的值  
    public int getBit(int index){   
        if(index <0 || index > length){   
            throw new IllegalArgumentException("length必须大于零小于" + length);   
        }   
        int intData = bits[index/32];   
        return (intData & bitValue[index%32]) >>> (32 - index%32 -1);   
    }   
    //设置index位的值，只能为0或者1   
    public void setBit(int index,int value){   
        if(index <0 || index > length){   
            throw new IllegalArgumentException("length必须大于零小于" + length);   
        }          
        if(value!=1&&value!=0){   
            throw new IllegalArgumentException("value必须为0或者1");   
        }   
        int intData = bits[index/32];   
        if(value == 1){   
            bits[index/32] = intData | bitValue[index%32];   
        }else{   
            bits[index/32] = intData & ~bitValue[index%32];   
        }   
    }   
    public int getLength(){   
        return length;   
    }      
}        
</pre>

bit数组有了，剩下就是算法代码，核心代码如下： 
<pre>
bitArray = new BitArray(100000000);    
//顺序读取所有的手机号码  
while((phoneNum = bufferedReader.readLine())!=null){   
    phoneNum = phoneNum.trim().substring(3);//13573228432   
    //取139后8位转换为int类型  
    phoneNumAsInt = Integer.valueOf(phoneNum);   
    //设置对应bit值为1   
    bitArray.setBit(phoneNumAsInt, 1);   
}      
//遍历bit数组输出所有存在的号码  
for(int i = 0;i<sortUnit;i++){   
    if(bitArray.getBit(i)==1){   
            writer.write("139" + leftPad(String.valueOf(i + sortUnit*times), 8));   
            writer.newLine();                          
    }                  
}   
writer.flush();    
</pre>

经测试，修改后的算法排序时只需要20多M的内存，一亿条电话号码排序只要10分钟（时间主要花在IO上），看来效果还是很明显的。 
    这个算法很快，不过也有他的局限性： 
    1.只能用于整数的排序，或者可以准确映射到正整数（对象不同对应的正整数也不相同）的数据的排序。 
    2.不能处理重复的数据，重复的数据排序后只有一条（如果有这种需求可以在这个算法的基础上修改，给出现次数大于1的数据添加个计数器，然后存入Map中） 
    3.对于数据量极其大的数据处理可能还是比较占用空间，这种情况可配合多通道排序算法解决。



++++多服务器共享 SESSION 的主要障碍及解决办法+++++++
通过了解 SESSION 的工作原理，我们可以发现，在默认情况下，各个服务器会各自分别对同一个客户端产生 SESSIONID，如
对于同一个用户浏览器，A 服务器产生的 SESSION ID 是30de1e9de3192ba6ce2992d27a1b6a0a，而 B 服务器生成的则是
c72665af28a8b14c0fe11afe3b59b51b。另外，PHP 的 SESSION数据都是分别保存在本服务器的文件系统中。
确定了问题所在之后，就可以着手进行解决了。想要共享 SESSION 数据，那就必须实现两个目标：一个是各个服务器对
同一个客户端产生的SESSION ID 必须相同，并且可通过同一个 COOKIE 进行传递，也就是说各个服务器必须可以读取同一个
名为 PHPSESSID的 COOKIE；另一个是 SESSION 数据的存储方式/位置必须保证各个服务器都能够访问到。简单地说就是
多服务器共享客户端的SESSION ID，同时还必须共享服务器端的 SESSION 数据。
第一个目标的实现其实很简单，只需要对 COOKIE 的域（domain）进行特殊地设置即可，默认情况下，COOKIE的域是当前
服务器的域名/IP 地址，而域不同的话，各个服务器所设置的 COOKIE 是不能相互访问的，如 www.aaa.com的服务器是
不能读写 www.bbb.com 服务器设置的 COOKIE的。这里我们所说的同一网站的服务器有其特殊性，那就是他们同属于同一个
一级域，如：tieba.xiaoyuan.com 和www.xiaoyuan.com 都属于域 .xiaoyuan.com，那么我们就可以设置 COOKIE 的
域为.xiaoyuan.com，这样 tieba.xiaoyuan.com、www.xiaoyuan.com 等等都可以访问此COOKIE。PHP 代码中的设置方法
如下：
<?php
ini_set('session.cookie_domain', '.xiaoyuan.com');
?>
这样各个服务器共享同一客户端 SESSION ID 的目的就达到了。

第二个目标的实现可以使用文件共享方式，有2种方式可以解决,一是用数据库存session,还有就是试用memcache。这里
用MEMCACHE来解决.