###算法的时间复杂度和空间复杂度合称为算法的复杂度
####1.时间复杂度
- 时间频度 一个算法执行所耗费的时间，从理论上是不能算出来的，必须上机运行测试才能知道。但我们不可能也没有必要对每个算法都上机测试，只需知道哪个算法花费的时间多，哪个算法花费的时间少就可以了。并且一个算法花费的时间与算法中语句的执行次数成正比例，哪个算法中语句执行次数多，它花费时间就多。一个算法中的语句执行次数称为语句频度或时间频度。记为T(n)。

- 时间复杂度 在刚才提到的时间频度中，n称为问题的规模，当n不断变化时，时间频度T(n)也会不断变化。但有时我们想知道它变化时呈现什么规律。为此，我们引入时间复杂度概念。 一般情况下，算法中基本操作重复执行的次数是问题规模n的某个函数，用T(n)表示，若有某个辅助函数f(n),使得当n趋近于无穷大时，T（n)/f(n)的极限值为不等于零的常数，则称f(n)是T(n)的同数量级函数。记作T(n)=Ｏ(f(n)),称Ｏ(f(n)) 为算法的渐进时间复杂度，简称时间复杂度。<br>
时间频度不同，但时间复杂度可能相同。如：T(n)=n2+3n+4与T(n)=4n2+2n+1它们的频度不同，但时间复杂度相同，都为O(n2)。
按数量级递增排列，常见的时间复杂度有：常数阶O(1),对数阶O(log2n),线性阶O(n), 线性对数阶O(nlog2n),平方阶O(n2)，立方阶O(n3),...， k次方阶O(nk),指数阶O(2n)。随着问题规模n的不断增大，上述时间复杂度不断增大，算法的执行效率越低。

- 最坏时间复杂度和平均时间复杂度 　最坏情况下的时间复杂度称最坏时间复杂度。一般不特别说明，讨论的时间复杂度均是最坏情况下的时间复杂度。 这样做的原因是：最坏情况下的时间复杂度是算法在任何输入实例上运行时间的上界，这就保证了算法的运行时间不会比任何更长。<br>
在最坏情况下的时间复杂度为T(n)=0(n)，它表示对于任何输入实例,该算法的运行时间不可能大于0(n)。 平均时间复杂度是指所有可能的输入实例均以等概率出现的情况下，算法的期望运行时间。<br>
指数阶0(2n)，显然，时间复杂度为指数阶0(2n)的算法效率极低，当n值稍大时就无法应用。
-  求时间复杂度

【1】如果算法的执行时间不随着问题规模n的增加而增长，即使算法中有上千条语句，其执行时间也不过是一个较大的常数。此类算法的时间复杂度是O(1)。
<pre>
x=91; y=100;
while(y>0) if(x>100) {x=x-10;y--;} else x++;
</pre>
解答： T(n)=O(1)，
这个程序看起来有点吓人，总共循环运行了1000次，但是我们看到n没有?
没。这段程序的运行是和n无关的，
就算它再循环一万年，我们也不管他，只是一个常数阶的函数

【2】当有若干个循环语句时，算法的时间复杂度是由嵌套层数最多的循环语句中最内层语句的频度f(n)决定的。
<pre>
 x=1; 
for(i=1;i<=n;i++) 
        for(j=1;j<=i;j++)
           for(k=1;k<=j;k++)
               x++; 　　
</pre>
该程序段中频度最大的语句是(5)，内循环的执行次数虽然与问题规模n没有直接关系，但是却与外层循环的变量取值有关，而最外层循环的次数直接与n有关，因此可以从内层循环向外层分析语句(5)的执行次数：  则该程序段的时间复杂度为T(n)=O(n3/6+低次项)=O(n3)

【3】算法的时间复杂度不仅仅依赖于问题的规模，还与输入实例的初始状态有关。
在数值A[0..n-1]中查找给定值K的算法大致如下：
<pre>   
i=n-1;            
while(i>=0&&(A[i]!=k))       
      i--;        
return i;  
</pre>      
此算法中的语句(3)的频度不仅与问题规模n有关，还与输入实例中A的各元素取值及K的取值有关: ①若A中没有与K相等的元素，则语句(3)的频度f(n)=n； ②若A的最后一个元素等于K,则语句(3)的频度f(n)是常数0。

- 时间复杂度评价性能 

有两个算法A1和A2求解同一问题，时间复杂度分别是T1(n)=100n2，T2(n)=5n3。（1）当输入量n＜20时，有T1(n)＞T2(n)，后者花费的时间较少。（2）随着问题规模n的增大，两个算法的时间开销之比5n3/100n2=n/20亦随着增大。即当问题规模较大时，算法A1比算法A2要有效地多。它们的渐近时间复杂度O(n2)和O(n3)从宏观上评价了这两个算法在时间方面的质量。在算法分析时，往往对算法的时间复杂度和渐近时间复杂度不予区分，而经常是将渐近时间复杂度T(n)=O(f(n))简称为时间复杂度，其中的f(n)一般是算法中频度最大的语句频度。
####2.空间复杂度
一个程序的空间复杂度是指运行完一个程序所需内存的大小。利用程序的空间复杂度，可以对程序的运行所需要的内存多少有个预先估计。一个程序执行时除了需要存储空间和存储本身所使用的指令、常数、变量和输入数据外，还需要一些对数据进行操作的工作单元和存储一些为现实计算所需信息的辅助空间。程序执行时所需存储空间包括以下两部分。　
　
- 固定部分。这部分空间的大小与输入/输出的数据的个数多少、数值无关。主要包括指令空间（即代码空间）、数据空间（常量、简单变量）等所占的空间。这部分属于静态空间。
- 可变空间，这部分空间的主要包括动态分配的空间，以及递归栈所需的空间等。这部分的空间大小与算法有关。<br>
一个算法所需的存储空间用f(n)表示。S(n)=O(f(n))　　其中n为问题的规模，S(n)表示空间复杂度。






#数据结构-算法-时间复杂度计算
###算法的时间复杂度定义为：
在进行算法分析时，语句总的执行次数T(n)是关于问题规模n的函数，进而分析T(n)随n的变化情况并确定T(n)的数量级。算法的时间复杂度，也就是算法的时间量度，记作：T(n}=0(f(n))。它表示随问题规模n的增大，算法执行时间的埔长率和 f(n)的埔长率相同，称作算法的渐近时间复杂度，简称为时间复杂度。其中f( n)是问题规横n的某个函数。
###根据定义，求解算法的时间复杂度的具体步骤是：

- ⑴ 找出算法中的基本语句；算法中执行次数最多的那条语句就是基本语句，通常是最内层循环的循环体。
- ⑵ 计算基本语句的执行次数的数量级；只需计算基本语句执行次数的数量级，这就意味着只要保证基本语句执行次数的函数中的最高次幂正确即可，可以忽略所有低次幂和最高次幂的系数。这样能够简化算法分析，并且使注意力集中在最重要的一点上：增长率。
- ⑶ 用大Ο记号表示算法的时间性能。将基本语句执行次数的数量级放入大Ο记号中。
####如何推导大o阶呢？我们给出了下面 的推导方法：

1. 用常数1取代运行时间中的所有加法常数。
2. 在修改后的运行次数函数中，只保留最髙阶项。
3. 如果最高阶项存在且不是1,则去除与这个项相乘的常数。

简单的说，就是保留求出次数的最高次幂，并且把系数去掉。  如T(n)=2n^2+n+1 =O(n^2)
<pre>
#include "stdio.h"  
  
int main()  
{  
    int i, j, x = 0, sum = 0, n = 100;  /* 执行1次 */  
    for( i = 1; i <= n; i++)    /* 执行n+1次 */  
    {  
        sum = sum + i;               /* 执行n次 */     
        for( j = 1; j <= n; j++)    /* 执行n*(n+1)次 */  
        {  
            x++;                /* 执行n*n次 */  
            sum = sum + x;      /* 执行n*n次 */  
        }  
    }  
    printf("%d", sum);          /* 执行1次 */  
}  
</pre> 
####按照上面推导“大O阶”的步骤，我们来看

- 第一步：“用常数 1 取代运行时间中的所有加法常数”，

则上面的算式变为：执行总次数 =3n^2 + 3n + 1

（直接相加的话,应该是T(n) = 1 + n+1 + n + n*(n+1) + n*n + n*n + 1 = 3n^2 + 3n + 3。现在用常数 1 取代运行时间中的所有加法常数，就是把T(n) = 3n^2 + 3n + 3中的最后一个3改为1. 就得到了 T(n) = 3n^2 + 3n + 1）

- 第二步：“在修改后的运行次数函数中，只保留最高阶项”。

这里的最高阶是 n 的二次方，所以算式变为：执行总次数 = 3n^2

- 第三步：“如果最高阶项存在且不是 1 ，则去除与这个项相乘的常数”。

这里 n 的二次方不是 1 所以要去除这个项的相乘常数，算式变为：执行总次数 = n^2

因此最后我们得到上面那段代码的算法时间复杂度表示为： O( n^2 )

下面我把常见的算法时间复杂度以及他们在效率上的高低顺序记录在这里，使大家对算法的效率有个直观的认识。

O(1) 常数阶 < O(logn) 对数阶 < O(n) 线性阶 < O(nlogn) < O(n^2) 平方阶 < O(n^3) < { O(2^n) < O(n!) < O(n^n) }

最后三项用大括号把他们括起来是想要告诉大家，如果日后大家设计的算法推导出的“大O阶”是大括号中的这几位，那么趁早放弃这个算法，在去研究新的算法出来吧。因为大括号中的这几位即便是在 n 的规模比较小的情况下仍然要耗费大量的时间，算法的时间复杂度大的离谱，基本上就是“不可用状态”。

###下面通过几个例子具体分析下时间复杂度计算过程。
####一、计算 1 + 2 + 3 + 4 + ...... + 100。
解决方法一：常规算法
<pre>
#include "stdio.h"  
  
int main()  
{  
    int i, sum = 0, n = 100;    /* 执行1次 */  
    for( i = 1; i <= n; i++) /* 执行 n+1 次 */  
    {  
        sum = sum + i;          /* 执行n次 */  
        //printf("%d \n", sum);  
    }  
    printf("%d", sum);          /* 执行1次 */  
}  
</pre>
从代码附加的注释可以看到所有代码都执行了多少次。那么这写代码语句执行次数的总和就可以理解为是该算法计算出结果所需要的时间。该算法所用的时间（算法语句执行的总次数）为： 1 + ( n + 1 ) + n + 1 = 2n + 3

而当 n 不断增大，比如我们这次所要计算的不是 1 + 2 + 3 + 4 + ...... + 100 = ？ 而是 1 + 2 + 3 + 4 + ...... + n = ？其中 n 是一个十分大的数字，那么由此可见，上述算法的执行总次数（所需时间）会随着 n 的增大而增加，但是在 for 循环以外的语句并不受 n 的规模影响（永远都只执行一次）。所以我们可以将上述算法的执行总次数简单的记做： 2n 或者简记 n

这样我们就得到了我们设计的算法的时间复杂度，我们把它记作： O(n)

解决方法二：高斯算法
<pre>
#include "stdio.h"  
  
int main()  
{  
    int sum = 0, n = 100;   /* 执行1次 */  
    sum = (1 + n) * n/2;    /* 执行1次 */  
  
    printf("%d", sum);      /* 执行1次 */  
}  
</pre>
这个算法的时间复杂度： O(3)，但一般记作 O(1)。

从感官上我们就不难看出，从算法的效率上看，O(1) < O(n) 的，所以高斯的算法更快，更优秀。
####二、求两个n阶方阵C=A*B的乘积
算法如下：
<pre>
//右边列为语句执行的频度  
  
   void MatrixMultiply(int A[n][n]，int B [n][n]，int C[n][n])  
  
   {  
  
(1) for(int i=0; i <n; i++)                         //n+1  
  
      {  
  
(2)      for (j=0;j < n; j++)                       //n*(n+1)  
  
           {  
  
(3)           C[i][j]=0;                            //n^2  
  
(4)           for (k=0; k<n; k++)                   //n^2*(n+1)  
  
               {  
  
(5)              C[i][j]=C[i][j]+A[i][k]*B[k][j];   //n^3  
  
              }  
  
          }  
  
      }  
  
  }  
</pre>
则该算法所有语句的频度之和为:

T(n) = 2n^3+3n^2+2n+1;  利用大O表示法,该算法的时间复杂度为O(n^3)。
####三、分析下列时间复杂度
<pre>
void test_(int n)  
{  
    i = 1, k = 100;  
    while (i<n)  
    {  
        k = k + 1;  
        i += 2;  
    }  
}  
</pre>
设for循环语句执行次数为T(n),则 i = 2T(n) + 1 <= n - 1,  即T(n) <= n/2 - 1 = O(n)
####四、分析下列时间复杂度
<pre>
void test_2(int b[]， int n)  
{  
    int i, j, k;  
    for (i=0; i<n-1; i++)  
    {  
        k = i;  
        for (j=i+1; j<n; j++)  
        {  
            if (b[k] > b[j])  
            {  
                k = j;  
            }  
        }  
        x = b[i];  
        b[i] = b[k];  
        b[k] = x;  
    }  
}  
</pre>
其中，算法的基本运算语句是
<pre>
if (b[k] > b[j])

{

   k = j;

}
</pre>
其执行次数T(n)为：

T(n) = n(n-1)/2=O(n²)

####五、分析下列时间复杂度
<pre>
void test_3(int n)  
{  
    int i = 0, s = 0;  
    while (s<n)  
    {  
        i++;  
        s = s + i;  
    }  
}  
</pre>
其中，算法的基本运算语句即while循环内部分，

设while循环语句执行次数为T(n),则

T(n) = O(√2)
####六、Hanoi(递归算法)时间复杂度分析
<pre>
void hanoi(int n, char a, char b, char c)  
{  
    if (n==1)  
    {  
        printf("move %d disk from %c to %c \n", n, a, c);  //执行一次  
    }  
    else  
    {  
        hanoi(n-1, a, c, b);    //递归n-1次  
        printf("move %d disk from %c to %c \n", n, a, c);  //执行一次  
        hanoi(n-1, b, a, c);    //递归n-1次  
    }  
}  
</pre>
对于递归函数的分析,跟设计递归函数一样，要先考虑基情况(比如hanoi中n==1时候),这样把一个大问题划分为多个子问题的求解。

故此上述算法的时间复杂度的递归关系如下:

	   
T(n) =1 当n=1时;T(n)=2T(n-1)+1 当n>1时

T(n) = 2T(n-1)+1 =2（2T（n-2） +1）+1 =2²T(n-2)+2²+1
= 2²(2T(n-3)+1)+2²+1 =2^3T(n-3)+2^3+1
=2^(n-1)T(1)+2^(n-1)+1=2^n+1
=O（2^n）


###求解算法的时间复杂度
求解算法的时间复杂度的具体步骤是：

　　⑴ 找出算法中的基本语句；

　　算法中执行次数最多的那条语句就是基本语句，通常是最内层循环的循环体。

　　⑵ 计算基本语句的执行次数的数量级；

　　只需计算基本语句执行次数的数量级，这就意味着只要保证基本语句执行次数的函数中的最高次幂正确即可，可以忽略所有低次幂和最高次幂的系数。这样能够简化算法分析，并且使注意力集中在最重要的一点上：增长率。

　　⑶ 用大Ο记号表示算法的时间性能。

　　将基本语句执行次数的数量级放入大Ο记号中。

　　如果算法中包含嵌套的循环，则基本语句通常是最内层的循环体，如果算法中包含并列的循环，则将并列循环的时间复杂度相加。例如：

　　for (i=1; i<=n; i++)
　　x++;

　　for (i=1; i<=n; i++)
　　for (j=1; j<=n; j++)
　　x++;

　　第一个for循环的时间复杂度为Ο(n)，第二个for循环的时间复杂度为Ο(n2)，则整个算法的时间复杂度为Ο(n+n2)=Ο(n2)。

　　常见的算法时间复杂度由小到大依次为：

　　Ο(1)＜Ο(log2n)＜Ο(n)＜Ο(nlog2n)＜Ο(n2)＜Ο(n3)＜…＜Ο(2n)＜Ο(n!)

Ο(1)表示基本语句的执行次数是一个常数，一般来说，只要算法中不存在循环语句，其时间复杂度就是Ο(1)。Ο(log2n)、Ο(n)、Ο(nlog2n)、Ο(n2)和Ο(n3)称为多项式时间，而Ο(2n)和Ο(n!)称为指数时间。计算机科学家普遍认为前者是有效算法，把这类问题称为P类问题，而把后者称为NP问题。

这只能基本的计算时间复杂度，具体的运行还会与硬件有关。

上面的这部分内容是比较可靠的，理解的时候，可以参看着下面的这部分内容。

在计算算法时间复杂度时有以下几个简单的程序分析法则:

1.对于一些简单的输入输出语句或赋值语句,近似认为需要O(1)时间

2.对于顺序结构,需要依次执行一系列语句所用的时间可采用大O下"求和法则"

求和法则:是指若算法的2个部分时间复杂度分别为 T1(n)=O(f(n))和 T2(n)=O(g(n)),则 T1(n)+T2(n)=O(max(f(n), g(n)))

特别地,若T1(m)=O(f(m)), T2(n)=O(g(n)),则 T1(m)+T2(n)=O(f(m) + g(n))

3.对于选择结构,如if语句,它的主要时间耗费是在执行then字句或else字句所用的时间,需注意的是检验条件也需要O(1)时间

4.对于循环结构,循环语句的运行时间主要体现在多次迭代中执行循环体以及检验循环条件的时间耗费,一般可用大O下"乘法法则"

乘法法则: 是指若算法的2个部分时间复杂度分别为 T1(n)=O(f(n))和 T2(n)=O(g(n)),则 T1*T2=O(f(n)*g(n))

5.对于复杂的算法,可以将它分成几个容易估算的部分,然后利用求和法则和乘法法则技术整个算法的时间复杂度

另外还有以下2个运算法则:

(1) 若g(n)=O(f(n)),则O(f(n))+ O(g(n))= O(f(n))

(2) O(Cf(n)) = O(f(n)),其中C是一个正常数

可以用以上法则对下面程序段进行简单分析

①for (i=0; i<n; i++)

② for (j=0; j<n; j++)

{

③ c[i][j] = 0;

④ for (k=0; k<n; k++)

⑤ c[i][j]= c[i][j]+ a[i][k]* b[k][j];/ * T5(n) = O(1) */

}

第①条与②③④⑤是循环嵌套T1(n)*T2(n)* (T3(n)+ T4(n)* T5(n))= O(n*n*n)即为整个算法的时间复杂度

O(1)<O(log2n)<O(n)<O(n log2 n)<O(n^2)<O(n^3)<O(2^n)
