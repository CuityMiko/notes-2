###高并发的业务架构

* 前端:异步请求+资源静态化+cdn
* 后端:请求队列+轮询分发+负载均衡+共享缓存
- 数据层:redis缓存+数据分表+写队列
- 存储:raid阵列+热备
- 网络:dns轮询+DDOS攻击防护

###基本上各种系统的架构选型就是在
- 可用性
- 数据一致性
- 实时性

这几个主要因素之间做权衡,次要问题是扩展性和成本.



##异步
异步的概念和同步相对。

与同步相对应，异步指的是让CPU暂时搁置当前请求的响应,处理下一个请求,当通过轮询或其他方式得到回调通知后,开始运行。多线程将异步操作放入另一线程中运行，通过轮询或回调方法得到完成通知,但是完成端口，由操作系统接管异步操作的调度，通过硬件中断，在完成时触发回调方法，此方式不需要占用额外线程。

###异步通信
在通信中，“异步通信”是一种很常用的通信方式。异步通信在发送字符时，所发送的字符之间的时间间隔可以是任意的。当然，接收端必须时刻做好接收的准备（如果接收端主机的电源都没有加上，那么发送端发送字符就没有意义，因为接收端根本无法接收）。发送端可以在任意时刻开始发送字符，因此必须在每一个字符的开始和结束的地方加上标志，即加上开始位和停止位，以便使接收端能够正确地将每一个字符接收下来。异步通信的好处是通信设备简单、便宜，但传输效率较低（因为开始位和停止位的开销所占比例较大）。

异步通信也可以是以帧作为发送的单位。接收端必须随时做好接收帧的准备。这时，帧的首部必须设有一些特殊的比特组合，使得接收端能够找出一帧的开始。这也称为帧定界。帧定界还包含确定帧的结束位置。这有两种方法。一种是在帧的尾部设有某种特殊的比特组合来标志帧的结束。或者在帧首部中设有帧长度的字段。需要注意的是，在异步发送帧时，并不是说发送端对帧中的每一个字符都必须加上开始位和停止位后再发送出去，而是说，发送端可以在任意时间发送一个帧，而帧与帧之间的时间间隔也可以是任意的。在一帧中的所有比特是连续发送的。发送端不需要在发送一帧之前和接收端进行协调（不需要先进行比特同步）。

###下面关于异步的是基于C#的情况下，其他情况也基本满足
C#中异步和多线程的区别是什么呢？异步和多线程两者都可以达到避免调用线程阻塞的目的，从而提高软件的可响应性。甚至有些时候我们就认为异步和多线程是等同的概念。但是，异步和多线程还是有一些区别的。而这些区别造成了使用异步和多线程的时机的区别。
- 异步操作的本质

所有的程序最终都会由计算机硬件来执行，所以为了更好的理解异步操作的本质，我们有必要了解一下它的硬件基础。 熟悉电脑硬件的朋友肯定对DMA这个词不陌生，硬盘、光驱的技术规格中都有明确DMA的模式指标，其实网卡、声卡、显卡也是有DMA功能的。DMA就是直 接内存访问的意思，也就是说，拥有DMA功能的硬件在和内存进行数据交换的时候可以不消耗CPU资源。只要CPU在发起数据传输时发送一个指令，硬件就开 始自己和内存交换数据，在传输完成之后硬件会触发一个中断来通知操作完成。这些无须消耗CPU时间的I/O操作正是异步操作的硬件基础。所以即使在DOS 这样的单进程（而且无线程概念）系统中也同样可以发起异步的DMA操作。

- 线程的本质

线程不是一个计算机硬件的功能，而是操作系统提供的一种逻辑功能，线程本质上是进程中一段并发运行的代码，所以线程需要操作系统投入CPU资源来运行和调度。

- 异步操作的优缺点

因为异步操作无须额外的线程负担，并且使用回调的方式进行处理，在设计良好的情况下，处理函数可以不必使用共享变量（即使无法完全不用，最起码可以减少 共享变量的数量），减少了死锁的可能。当然异步操作也并非完美无暇。编写异步操作的复杂程度较高，程序主要使用回调方式进行处理，与普通人的思维方式有些出入，而且难以调试。

- 多线程的优缺点

多线程的优点很明显，线程中的处理程序依然是顺序执行，符合普通人的思维习惯，所以编程简单。但是多线程的缺点也同样明显，线程的使用（滥用）会给系统带来上下文切换的额外负担。并且线程间的共享变量可能造成死锁的出现。

- 适用范围

在了解了线程与异步操作各自的优缺点之后，我们可以来探讨一下线程和异步的合理用途。我认为：当需要执行I/O操作时，使用异步操作比使用线程+同步 I/O操作更合适。I/O操作不仅包括了直接的文件、网络的读写，还包括数据库操作、Web Service、HttpRequest以及.net Remoting等跨进程的调用。

而线程的适用范围则是那种需要长时间CPU运算的场合，例如耗时较长的图形处理和算法执行。但是往往由于使用线程编程的简单和符合习惯，所以很多朋友往往会使用线程来执行耗时较长的I/O操作。这样在只有少数几个并发操作的时候还无伤大雅，如果需要处理大量的并发操作时就不合适了。

###多线程磁盘读写效率
多线程磁盘读写效率（由于磁盘寻道随机性增加而导致I/O效率呈线性下降）。

###共享内存
顾名思义，共享内存就是允许两个不相关的进程访问同一个逻辑内存。共享内存是在两个正在运行的进程之间共享和传递数据的一种非常有效的方式。不同进程之间共享的内存通常安排为同一段物理内存。进程可以将同一段共享内存连接到它们自己的地址空间中，所有进程都可以访问共享内存中的地址，就好像它们是由用C语言函数malloc分配的内存一样。而如果某个进程向共享内存写入数据，所做的改动将立即影响到可以访问同一段共享内存的任何其他进程。

###后端杂题

- 分布式key/value存储要如何保证映射可靠，答：通过中心代理来负责映射。、
- 如果不同的例程都要向某个key更新更大的value值，如何在不用信号量，同步锁这些的情况下保证最终value是最大的(同步，set get循环巧妙)。
- 后面问了个海量数据中找第k大数(1.其实可以直接采用桶划分，即使是64位也最多三次遍历就可以了。2.也可以采用位滤除，但磁盘操作太多 3.k堆滤除，但k如果太大会频繁交换内存 4.分配到多机，多机同时外存排序，并有另外一台机子作多路归并）
- TCP的黏包现象。一个是nagle算法，一个是应用层数据的包无边界问题，这是无法解决的，因为TCP管不到应用层的事，它只负责按字节流传输。

##决定后端性能的几个关键点
在异步框架中，CPU本身是不会被IO阻塞的，而我们所关注的点就来到了：<br>
CPU消耗的主要点
- 字符串操作（尝试流）
- 内存操作（内存池）
- 数据结构设计（红黑树换HASHMAP）

并发的处理

- 锁的临界区减少（仅在必要时加小粒度锁）
- 队列化（无锁）
- 计算、存储、网络的权衡
- 合理的将网络、计算的开销减小，增大存储的开销（缓存）
- 更合理的调度（docker、云化）

性能的极限在于“平衡”：

- 计算、存储、网络，三者要做到平衡
- 大部分计算、网络的瓶颈都可以用增大存储来解决，但要有度
- 

大部分的性能 state-of-art （一台普通 4 核服务器）：

- 这台服务器的最大报文数在~50w/s （和服务器年份有关）
- 通过 C10M （ dpdk 、 netmap ）等技术可以达到 1kw+/s 的最大报文数，然而目前并没有太多卵用
- thrift 、 grpc 这类框架，一个业务逻辑较轻的服务 TPS 大概能到上万（后台服务标准）
- 分词、分类（ SVM 等），文本处理等 CPU 密集型的业务， TPS 大多只能到百级
- 特殊的：只要内存足够，长连接服务上 C10M 很轻松

###Golang的垃圾回收机制GC停止的原因
golang垃圾回收时暂停程序防止收集时产生新的垃圾

###java线程与golang协程区别|golang并发与java并发的区别
NIO（非阻塞IO）是一种IO编程模型，Golang中的IO底层实现方式和java NIO模型一致，通俗点说就是都采用了EPOLL。 你在使用golang读文件的时候，goroutine 会默默的挂起，只是你不知道，当读完毕了，goroutine 再次恢复，但你不用担心，goroutine 的挂起和恢复没有java线程那样可怕，你可以认为goroutine 的挂起和恢复就是保存和恢复几个变量的值，其实也是这样的。

剩下的就是goroutine 和 java线程的区别了，goroutine是用户态的线程切换，java采用的是系统线程切换，用汇编语言描述是一个(java)调用int 80软中断,一个没有。 意味着goroutine更轻量级，可以同时相应成千上万的线程切换，java你创造上千个线程就有些吃力了。

因为java线程不能创造过多的线程，如果同时处理上万上千的请求时候，就要考虑在几十个线程来处理上万上千的请求，这就出现了很多请求和线程不可能一一对应，所以通常做法是每个线程分别处理单个请求各个阶段。好比流水线，请求是要加工的商品，每个线程处理一道工序，这样做的好处是每人都做自己熟悉的，对于程序来说每个线程执行的代码永远都是自己很短的一块，这样根据局部优化原理，更具备CPU，内存亲和力，利于JIT。说这样多，就是说如果线程和请求不能一一对应，流水线式的并发编程很麻烦，阅读性也很差，通常是线程A里面一段逻辑代码，线程B又有另一处处理的逻辑代码。

由于goroutine 的轻便，你可以将请求和goroutine 一一对应起来，不用考虑将请求在线程之间换来换去，只关心你的业务逻辑，这就是goroutine 的好处。

总结：

golang的goroutine让你比java更容易编写并发程序，但性能不会有差别（目前来说，golang性能还不能和java比，看过代码就知道了，GC弱到爆），代码不会减少，该写的逻辑还得写。ps，其实golang的(sched)go程切换代码虽然原理和java的fork-join框架一样，但是fork-join比golang的sched代码牛逼不少，开始膜拜Doug Lea吧，golang还有很长的路要走。

###Golang中的协程与进程
线程是操作系统调度的, 抢占式的；协程是应用自己调度的.

###QPS与TPS
QPS：Queries Per Second意思是"每秒查询率"，是一台服务器每秒能够相应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。

TPS：TransactionsPerSecond的缩写，也就是"事务数/秒"。它是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器 做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数，最终利用这些信息来估计得分。客户机使 用加权协函数平均方法来计算客户机的得分，测试软件就是利用客户机的这些信息使用加权协函数平均方法来计算服务器端的整体TPS得分。

###泛型
我们在编写程序时，经常遇到两个模块的功能非常相似，只是一个是处理int数据，另一个是处理string数据，或者其他自定义的数据类型，但我们没有办法，只能分别写多个方法处理每个数据类型，因为方法的参数类型不同。有没有一种办法，在方法中传入通用的数据类型，这样不就可以合并代码了吗？泛型的出现就是专门解决这个问题的。

通过使用泛型类型参数T，您可以编写其他客户端代码能够使用的单个类，而不致引入运行时强制转换或装箱操作的成本或风险 使用泛型类型可以最大限度地重用代码、保护类型的安全以及提高性能 泛型最常见的用途是创建集合类。

使用泛型可以最大限度的重用代码，保护类型的安全以及提高性能。

###Future，Promise与Delay并发编程的设计模式
其它语言中Future和Promise的概念大量存在， 比如Node.js、Scala、Java、C#、C++ 11、Scheme、Swift等，可以方便的实现异步执行和回调。但是在Go语言的世界里，我们是通过goroutine/channel实现这种类似的功能。

Future，Promise或Delay是用于并发编程的一种设计模式。它们表示一个对象，这个对象用来作为一次计算结果的代理，而该结果开始的时候是未知的，因为计算还没有完成。Promise与Future的区别在于，Future是Promise的一个只读的视图，也就是说Future没有设置任务结果的方法，只能获取任务执行结果或者为Future添加回调函数。